From 4cf3d7cdbaf93f460db278524c6339b67684d913 Mon Sep 17 00:00:00 2001
From: kknitin <nitin.kulkarni@mindmusiclabs.com>
Date: Tue, 1 Oct 2019 13:54:37 +0200
Subject: [PATCH 2/2] fix for RT safe dma

---
 drivers/dma/Kconfig           |   6 ++
 drivers/dma/bcm2835-dma.c     | 126 ++++++++++++++++++++++++++++++----
 drivers/dma/virt-dma.c        |  17 ++---
 drivers/dma/virt-dma.h        |  16 +++--
 drivers/irqchip/irq-bcm2835.c |  15 +++-
 5 files changed, 150 insertions(+), 30 deletions(-)

diff --git a/drivers/dma/Kconfig b/drivers/dma/Kconfig
index 845fb2ff22a2..b7e33d3738c1 100644
--- a/drivers/dma/Kconfig
+++ b/drivers/dma/Kconfig
@@ -135,6 +135,12 @@ config DMA_BCM2835
 	select DMA_ENGINE
 	select DMA_VIRTUAL_CHANNELS
 
+config BCM_RTDM_IRQ_TX
+	int "IRQ number of the RT DMA tx channel"
+
+config BCM_RTDM_IRQ_RX
+	int "IRQ number of the RT DMA rx channel"
+
 config DMA_JZ4740
 	tristate "JZ4740 DMA support"
 	depends on MACH_JZ4740 || COMPILE_TEST
diff --git a/drivers/dma/bcm2835-dma.c b/drivers/dma/bcm2835-dma.c
index babfed97b22c..d8ed5d15b2c7 100644
--- a/drivers/dma/bcm2835-dma.c
+++ b/drivers/dma/bcm2835-dma.c
@@ -44,6 +44,9 @@
 #include <linux/spinlock.h>
 #include <linux/of.h>
 #include <linux/of_dma.h>
+#include <rtdm/driver.h>
+#include <linux/delay.h>
+#include <asm/barrier.h>
 
 #include "virt-dma.h"
 
@@ -181,6 +184,12 @@ struct bcm2835_desc {
 #define MAX_DMA_LEN SZ_1G
 #define MAX_LITE_DMA_LEN (SZ_64K - 4)
 
+
+/***********************************************************************/
+static rtdm_irq_t  dma_rtdm_tx_irq;
+static rtdm_irq_t  dma_rtdm_rx_irq;
+/***********************************************************************/
+
 static inline size_t bcm2835_dma_max_frame_length(struct bcm2835_chan *c)
 {
 	/* lite and normal channels have different max frame length */
@@ -367,8 +376,9 @@ static struct bcm2835_desc *bcm2835_dma_create_cb_chain(
 			d->cb_list[frame - 1].cb->next = cb_entry->paddr;
 
 		/* update src and dst and length */
-		if (src && (info & BCM2835_DMA_S_INC))
+		if (src && (info & BCM2835_DMA_S_INC)) {
 			src += control_block->length;
+		}
 		if (dst && (info & BCM2835_DMA_D_INC))
 			dst += control_block->length;
 
@@ -464,6 +474,60 @@ static void bcm2835_dma_start_desc(struct bcm2835_chan *c)
 	writel(BCM2835_DMA_ACTIVE, c->chan_base + BCM2835_DMA_CS);
 }
 
+static void bcm2835_chan_complete_cyclic(struct virt_dma_desc *vd)
+{
+	struct virt_dma_chan *vc = to_virt_chan(vd->tx.chan);
+
+	vc->cyclic = vd;
+	vchan_complete((unsigned long)vc);
+}
+
+static void bcm2835_chan_complete(struct virt_dma_desc *vd)
+{
+	struct virt_dma_chan *vc = to_virt_chan(vd->tx.chan);
+	dma_cookie_t cookie;
+
+	cookie = vd->tx.cookie;
+	dma_cookie_complete(&vd->tx);
+	dev_vdbg(vc->chan.device->dev, "txd %p[%x]: marked complete\n",
+		 vd, cookie);
+	list_add_tail(&vd->node, &vc->desc_completed);
+
+	vchan_complete((unsigned long)vc);
+}
+
+static int bcm2835_dma_rtcallback(rtdm_irq_t *irqh)
+{
+	struct bcm2835_chan *c = rtdm_irq_get_arg(irqh, struct bcm2835_chan);
+	struct bcm2835_desc *d;
+	unsigned long flags;
+
+	//raw_spin_lock_irqsave(&c->vc.lock, flags);
+
+	/* Acknowledge interrupt */
+	writel(BCM2835_DMA_INT, c->chan_base + BCM2835_DMA_CS);
+
+	d = c->desc;
+
+	if (d) {
+		if (d->cyclic) {
+			/* call the cyclic callback */
+			bcm2835_chan_complete_cyclic(&d->vd);
+
+			/* Keep the DMA engine running */
+			writel(BCM2835_DMA_ACTIVE,
+			       c->chan_base + BCM2835_DMA_CS);
+		} else {
+			bcm2835_chan_complete(&c->desc->vd);
+			bcm2835_dma_start_desc(c);
+		}
+	}
+
+	//raw_spin_unlock_irqrestore(&c->vc.lock, flags);
+
+	return RTDM_IRQ_HANDLED;
+}
+
 static irqreturn_t bcm2835_dma_callback(int irq, void *data)
 {
 	struct bcm2835_chan *c = data;
@@ -479,7 +543,7 @@ static irqreturn_t bcm2835_dma_callback(int irq, void *data)
 			return IRQ_NONE;
 	}
 
-	spin_lock_irqsave(&c->vc.lock, flags);
+	raw_spin_lock_irqsave(&c->vc.lock, flags);
 
 	/*
 	 * Clear the INT flag to receive further interrupts. Keep the channel
@@ -503,7 +567,7 @@ static irqreturn_t bcm2835_dma_callback(int irq, void *data)
 		}
 	}
 
-	spin_unlock_irqrestore(&c->vc.lock, flags);
+	raw_spin_unlock_irqrestore(&c->vc.lock, flags);
 
 	return IRQ_HANDLED;
 }
@@ -512,6 +576,8 @@ static int bcm2835_dma_alloc_chan_resources(struct dma_chan *chan)
 {
 	struct bcm2835_chan *c = to_bcm2835_dma_chan(chan);
 	struct device *dev = c->vc.chan.device->dev;
+	static rtdm_irq_t *rtdm_irq_handle;
+	int ret;
 
 	dev_dbg(dev, "Allocating DMA channel %d\n", c->ch);
 
@@ -522,6 +588,22 @@ static int bcm2835_dma_alloc_chan_resources(struct dma_chan *chan)
 		return -ENOMEM;
 	}
 
+	if (c->irq_number == CONFIG_BCM_RTDM_IRQ_TX ||
+				c->irq_number == CONFIG_BCM_RTDM_IRQ_RX) {
+
+		if (c->irq_number == CONFIG_BCM_RTDM_IRQ_TX)
+			rtdm_irq_handle = &dma_rtdm_tx_irq;
+		else
+			rtdm_irq_handle = &dma_rtdm_rx_irq;
+
+		ret = rtdm_irq_request(rtdm_irq_handle, c->irq_number,
+					bcm2835_dma_rtcallback,
+			       		0, "DMA TX IRQ", c);
+		if (ret) {
+			printk("rt irq request failed !\n");
+		}
+		return ret;
+	}
 	return request_irq(c->irq_number, bcm2835_dma_callback,
 			   c->irq_flags, "DMA IRQ", c);
 }
@@ -529,12 +611,26 @@ static int bcm2835_dma_alloc_chan_resources(struct dma_chan *chan)
 static void bcm2835_dma_free_chan_resources(struct dma_chan *chan)
 {
 	struct bcm2835_chan *c = to_bcm2835_dma_chan(chan);
+	static rtdm_irq_t *rtdm_irq_handle;
 
 	vchan_free_chan_resources(&c->vc);
+
+	if (c->irq_number == CONFIG_BCM_RTDM_IRQ_TX ||
+				c->irq_number == CONFIG_BCM_RTDM_IRQ_RX) {
+
+		if (c->irq_number == CONFIG_BCM_RTDM_IRQ_TX)
+			rtdm_irq_handle = &dma_rtdm_tx_irq;
+		else
+			rtdm_irq_handle = &dma_rtdm_rx_irq;
+		rtdm_irq_free(rtdm_irq_handle);
+		dma_pool_destroy(c->cb_pool);
+		printk("rt irq freed !\n");
+	} else {
 	free_irq(c->irq_number, c);
 	dma_pool_destroy(c->cb_pool);
 
 	dev_dbg(c->vc.chan.device->dev, "Freeing DMA channel %u\n", c->ch);
+	}
 }
 
 static size_t bcm2835_dma_desc_size(struct bcm2835_desc *d)
@@ -578,7 +674,7 @@ static enum dma_status bcm2835_dma_tx_status(struct dma_chan *chan,
 	if (ret == DMA_COMPLETE || !txstate)
 		return ret;
 
-	spin_lock_irqsave(&c->vc.lock, flags);
+	raw_spin_lock_irqsave(&c->vc.lock, flags);
 	vd = vchan_find_desc(&c->vc, cookie);
 	if (vd) {
 		txstate->residue =
@@ -587,10 +683,12 @@ static enum dma_status bcm2835_dma_tx_status(struct dma_chan *chan,
 		struct bcm2835_desc *d = c->desc;
 		dma_addr_t pos;
 
-		if (d->dir == DMA_MEM_TO_DEV)
+		if (d->dir == DMA_MEM_TO_DEV) {
 			pos = readl(c->chan_base + BCM2835_DMA_SOURCE_AD);
-		else if (d->dir == DMA_DEV_TO_MEM)
+		}
+		else if (d->dir == DMA_DEV_TO_MEM) {
 			pos = readl(c->chan_base + BCM2835_DMA_DEST_AD);
+		}
 		else
 			pos = 0;
 
@@ -599,7 +697,7 @@ static enum dma_status bcm2835_dma_tx_status(struct dma_chan *chan,
 		txstate->residue = 0;
 	}
 
-	spin_unlock_irqrestore(&c->vc.lock, flags);
+	raw_spin_unlock_irqrestore(&c->vc.lock, flags);
 
 	return ret;
 }
@@ -609,11 +707,11 @@ static void bcm2835_dma_issue_pending(struct dma_chan *chan)
 	struct bcm2835_chan *c = to_bcm2835_dma_chan(chan);
 	unsigned long flags;
 
-	spin_lock_irqsave(&c->vc.lock, flags);
+	raw_spin_lock_irqsave(&c->vc.lock, flags);
 	if (vchan_issue_pending(&c->vc) && !c->desc)
 		bcm2835_dma_start_desc(c);
 
-	spin_unlock_irqrestore(&c->vc.lock, flags);
+	raw_spin_unlock_irqrestore(&c->vc.lock, flags);
 }
 
 static struct dma_async_tx_descriptor *bcm2835_dma_prep_dma_memcpy(
@@ -797,12 +895,12 @@ static int bcm2835_dma_terminate_all(struct dma_chan *chan)
 	unsigned long flags;
 	LIST_HEAD(head);
 
-	spin_lock_irqsave(&c->vc.lock, flags);
+	raw_spin_lock_irqsave(&c->vc.lock, flags);
 
 	/* Prevent this channel being scheduled */
-	spin_lock(&d->lock);
+	raw_spin_lock(&d->lock);
 	list_del_init(&c->node);
-	spin_unlock(&d->lock);
+	raw_spin_unlock(&d->lock);
 
 	/* stop DMA activity */
 	if (c->desc) {
@@ -812,7 +910,7 @@ static int bcm2835_dma_terminate_all(struct dma_chan *chan)
 	}
 
 	vchan_get_all_descriptors(&c->vc, &head);
-	spin_unlock_irqrestore(&c->vc.lock, flags);
+	raw_spin_unlock_irqrestore(&c->vc.lock, flags);
 	vchan_dma_desc_free_list(&c->vc, &head);
 
 	return 0;
@@ -934,7 +1032,7 @@ static int bcm2835_dma_probe(struct platform_device *pdev)
 	od->ddev.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;
 	od->ddev.dev = &pdev->dev;
 	INIT_LIST_HEAD(&od->ddev.channels);
-	spin_lock_init(&od->lock);
+	raw_spin_lock_init(&od->lock);
 
 	platform_set_drvdata(pdev, od);
 
diff --git a/drivers/dma/virt-dma.c b/drivers/dma/virt-dma.c
index 545e97279083..009802e3087f 100644
--- a/drivers/dma/virt-dma.c
+++ b/drivers/dma/virt-dma.c
@@ -26,11 +26,11 @@ dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *tx)
 	unsigned long flags;
 	dma_cookie_t cookie;
 
-	spin_lock_irqsave(&vc->lock, flags);
+	raw_spin_lock_irqsave(&vc->lock, flags);
 	cookie = dma_cookie_assign(tx);
 
 	list_move_tail(&vd->node, &vc->desc_submitted);
-	spin_unlock_irqrestore(&vc->lock, flags);
+	raw_spin_unlock_irqrestore(&vc->lock, flags);
 
 	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: submitted\n",
 		vc, vd, cookie);
@@ -55,9 +55,9 @@ int vchan_tx_desc_free(struct dma_async_tx_descriptor *tx)
 	struct virt_dma_desc *vd = to_virt_desc(tx);
 	unsigned long flags;
 
-	spin_lock_irqsave(&vc->lock, flags);
+	raw_spin_lock_irqsave(&vc->lock, flags);
 	list_del(&vd->node);
-	spin_unlock_irqrestore(&vc->lock, flags);
+	raw_spin_unlock_irqrestore(&vc->lock, flags);
 
 	dev_dbg(vc->chan.device->dev, "vchan %p: txd %p[%x]: freeing\n",
 		vc, vd, vd->tx.cookie);
@@ -83,14 +83,14 @@ EXPORT_SYMBOL_GPL(vchan_find_desc);
  * This tasklet handles the completion of a DMA descriptor by
  * calling its callback and freeing it.
  */
-static void vchan_complete(unsigned long arg)
+void vchan_complete(unsigned long arg)
 {
 	struct virt_dma_chan *vc = (struct virt_dma_chan *)arg;
 	struct virt_dma_desc *vd, *_vd;
 	struct dmaengine_desc_callback cb;
 	LIST_HEAD(head);
 
-	spin_lock_irq(&vc->lock);
+	//raw_spin_lock_irq(&vc->lock);
 	list_splice_tail_init(&vc->desc_completed, &head);
 	vd = vc->cyclic;
 	if (vd) {
@@ -99,7 +99,7 @@ static void vchan_complete(unsigned long arg)
 	} else {
 		memset(&cb, 0, sizeof(cb));
 	}
-	spin_unlock_irq(&vc->lock);
+	//raw_spin_unlock_irq(&vc->lock);
 
 	dmaengine_desc_callback_invoke(&cb, NULL);
 
@@ -115,6 +115,7 @@ static void vchan_complete(unsigned long arg)
 		dmaengine_desc_callback_invoke(&cb, NULL);
 	}
 }
+EXPORT_SYMBOL_GPL(vchan_complete);
 
 void vchan_dma_desc_free_list(struct virt_dma_chan *vc, struct list_head *head)
 {
@@ -136,7 +137,7 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev)
 {
 	dma_cookie_init(&vc->chan);
 
-	spin_lock_init(&vc->lock);
+	raw_spin_lock_init(&vc->lock);
 	INIT_LIST_HEAD(&vc->desc_allocated);
 	INIT_LIST_HEAD(&vc->desc_submitted);
 	INIT_LIST_HEAD(&vc->desc_issued);
diff --git a/drivers/dma/virt-dma.h b/drivers/dma/virt-dma.h
index 3f776a46a29c..a3e18f91e88f 100644
--- a/drivers/dma/virt-dma.h
+++ b/drivers/dma/virt-dma.h
@@ -26,8 +26,11 @@ struct virt_dma_chan {
 	struct tasklet_struct task;
 	void (*desc_free)(struct virt_dma_desc *);
 
-	spinlock_t lock;
-
+#ifdef CONFIG_IPIPE
+	ipipe_spinlock_t lock;
+#else
+	raw_spinlock_t lock;
+#endif
 	/* protected by vc.lock */
 	struct list_head desc_allocated;
 	struct list_head desc_submitted;
@@ -47,6 +50,7 @@ void vchan_init(struct virt_dma_chan *vc, struct dma_device *dmadev);
 struct virt_dma_desc *vchan_find_desc(struct virt_dma_chan *, dma_cookie_t);
 extern dma_cookie_t vchan_tx_submit(struct dma_async_tx_descriptor *);
 extern int vchan_tx_desc_free(struct dma_async_tx_descriptor *);
+extern void vchan_complete(unsigned long arg);
 
 /**
  * vchan_tx_prep - prepare a descriptor
@@ -64,9 +68,9 @@ static inline struct dma_async_tx_descriptor *vchan_tx_prep(struct virt_dma_chan
 	vd->tx.tx_submit = vchan_tx_submit;
 	vd->tx.desc_free = vchan_tx_desc_free;
 
-	spin_lock_irqsave(&vc->lock, flags);
+	raw_spin_lock_irqsave(&vc->lock, flags);
 	list_add_tail(&vd->node, &vc->desc_allocated);
-	spin_unlock_irqrestore(&vc->lock, flags);
+	raw_spin_unlock_irqrestore(&vc->lock, flags);
 
 	return &vd->tx;
 }
@@ -152,11 +156,11 @@ static inline void vchan_free_chan_resources(struct virt_dma_chan *vc)
 	unsigned long flags;
 	LIST_HEAD(head);
 
-	spin_lock_irqsave(&vc->lock, flags);
+	raw_spin_lock_irqsave(&vc->lock, flags);
 	vchan_get_all_descriptors(vc, &head);
 	list_for_each_entry(vd, &head, node)
 		dmaengine_desc_clear_reuse(&vd->tx);
-	spin_unlock_irqrestore(&vc->lock, flags);
+	raw_spin_unlock_irqrestore(&vc->lock, flags);
 
 	vchan_dma_desc_free_list(vc, &head);
 }
diff --git a/drivers/irqchip/irq-bcm2835.c b/drivers/irqchip/irq-bcm2835.c
index ec07012a2a2a..34212161542e 100644
--- a/drivers/irqchip/irq-bcm2835.c
+++ b/drivers/irqchip/irq-bcm2835.c
@@ -50,6 +50,7 @@
 #include <linux/of_irq.h>
 #include <linux/irqchip.h>
 #include <linux/irqdomain.h>
+#include <linux/ipipe.h>
 
 #include <asm/exception.h>
 #ifndef CONFIG_ARM64
@@ -341,9 +342,19 @@ static void __exception_irq_entry bcm2835_handle_irq(
 static void bcm2836_chained_handle_irq(struct irq_desc *desc)
 {
 	u32 hwirq;
-
-	while ((hwirq = get_next_armctrl_hwirq()) != ~0)
+	int irq;
+
+	while ((hwirq = get_next_armctrl_hwirq()) != ~0) {
+		irq = irq_linear_revmap(intc.domain, hwirq);
+		if(irq == CONFIG_BCM_RTDM_IRQ_TX || irq ==
+		CONFIG_BCM_RTDM_IRQ_RX ) {
+			ipipe_trace_irq_entry(irq);
+			__ipipe_dispatch_irq(irq, IPIPE_IRQF_NOACK);
+			ipipe_trace_irq_exit(irq);;
+			continue;
+		}
 		ipipe_handle_demuxed_irq(irq_linear_revmap(intc.domain, hwirq));
+	}
 }
 
 IRQCHIP_DECLARE(bcm2835_armctrl_ic, "brcm,bcm2835-armctrl-ic",
-- 
2.17.1

